{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tfN515X1SFR044GbrNi2AlObISw_4C5J",
      "authorship_tag": "ABX9TyNZe4l48ezLvKVK2KwY5JWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farazlfc/Quant-Learnings-and-Experiments/blob/main/pseduo_hangman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "qC3UuvmNSOl9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JQliX3KyRHvS"
      },
      "outputs": [],
      "source": [
        "dictionary_path = \"/content/drive/MyDrive/trexquant/words_250000_train.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_dict = []\n",
        "with open(dictionary_path, 'r') as file_:\n",
        "  for x in file_:\n",
        "    words_dict.append(x.strip())"
      ],
      "metadata": {
        "id": "hd0nT8GQRnEe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_dict[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Efw3qwoRuah",
        "outputId": "e527ef90-07d3-45b7-c779-0ed69728eb37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aaa', 'aaaaaa', 'aaas', 'aachen', 'aaee', 'aag', 'aahed', 'aahs', 'aal', 'aalesund', 'aaliis', 'aalst', 'aam', 'aandahl', 'aao', 'aapss', 'aar', 'aarau', 'aardvark', 'aardwolf', 'aaren', 'aargh', 'aarika', 'aaronic', 'aaronite', 'aaronsburg', 'aarp', 'aarrghh', 'aas', 'aasvogels', 'aaup', 'aavso', 'aba', 'ababdeh', 'abac', 'abacas', 'abacaxi', 'abaci', 'abacination', 'abaciscus', 'aback', 'abaco', 'abacterial', 'abactinally', 'abactor', 'abaculus', 'abacuses', 'abada', 'abaddon', 'abadengo', 'abadite', 'abaft', 'abagail', 'abailard', 'abaised', 'abaisse', 'abaka', 'abakas', 'abalation', 'abalienated', 'abalienation', 'abalones', 'abamp', 'abamperes', 'abana', 'abandon', 'abandoned', 'abandonee', 'abandoners', 'abandonment', 'abandons', 'abanet', 'abanic', 'abantes', 'abaptiston', 'abarambo', 'abaris', 'abarticular', 'abas', 'abased', 'abasedness', 'abasements', 'abasers', 'abasgi', 'abashed', 'abashedness', 'abashing', 'abashlessly', 'abashments', 'abasias', 'abasing', 'abask', 'abassieh', 'abastard', 'abastral', 'abatage', 'abated', 'abatements', 'abaters', 'abatic', 'abatis', 'abatises', 'abatjours', 'abator', 'abats', 'abattis', 'abattises', 'abattoirs', 'abattue', 'abature', 'abave', 'abaxile', 'abayah', 'abb', 'abbacies', 'abbacy', 'abbai', 'abbas', 'abbasid', 'abbassid', 'abbate', 'abbatical', 'abbaye', 'abbes', 'abbesses', 'abbevilean', 'abbevillian', 'abbeys', 'abbeystede', 'abbie', 'abbogada', 'abbotcies', 'abbotnullius', 'abbots', 'abbotsford', 'abbotships', 'abbotsun', 'abbottson', 'abboud', 'abbr', 'abbreviatable', 'abbreviated', 'abbreviates', 'abbreviation', 'abbreviator', 'abbreviatory', 'abbroachment', 'abbye', 'abc', 'abcissa', 'abcs', 'abdal', 'abdaria', 'abdel', 'abderhalden', 'abderite', 'abdest', 'abdicable', 'abdicate', 'abdicates', 'abdication', 'abdicative', 'abdiel', 'abditory', 'abdomen', 'abdomina', 'abdominales', 'abdominalian', 'abdominals', 'abdominocardiac', 'abdominocystic', 'abdominohysterectomy', 'abdominoposterior', 'abdominoscopy', 'abdominous', 'abdominovaginal', 'abdon', 'abduce', 'abducens', 'abducentes', 'abducing', 'abducted', 'abduction', 'abductor', 'abductors', 'abdul', 'abdulbaha', 'abe', 'abear', 'abebi', 'abecedaria', 'abecedarians', 'abecedarium', 'abecedary', 'abede', 'abednego', 'abeigh', 'abelard', 'abeles', 'abelian', 'abelite', 'abelmoschus', 'abelmosks', 'abelonian', 'abeltree', 'abend', 'abenezra', 'abeokuta', 'abepp', 'abercromby', 'aberdavine', 'aberdeenshire', 'aberdonian', 'aberfan', 'aberia', 'abernathy', 'abernon', 'aberrance', 'aberrancy', 'aberrantly', 'aberrate', 'aberrating', 'aberrational', 'aberrative', 'aberrometer', 'abert', 'aberuncator', 'abesse', 'abet', 'abetments', 'abettal', 'abetted', 'abetters', 'abettor', 'abeu', 'abey', 'abeyances', 'abeyancy', 'abfarad', 'abfm', 'abhc', 'abhenry', 'abhinaya', 'abhominable', 'abhorred', 'abhorrences', 'abhorrent', 'abhorrer', 'abhorrible', 'abhors', 'abi', 'abiathar', 'abichite', 'abidance', 'abidden', 'abided', 'abiders', 'abidi', 'abidingly', 'abidjan', 'abied', 'abience', 'abies', 'abietene', 'abietin', 'abietineous', 'abietite', 'abigael', 'abigails', 'abigale', 'abigei', 'abihu', 'abilao', 'abiliment', 'abilities', 'abilla', 'abilyne', 'abimelech', 'abingdon', 'abington', 'abinoem', 'abiogeneses', 'abiogenesist', 'abiogenetical', 'abiogenist', 'abiogeny', 'abiologically', 'abioses', 'abiotic', 'abiotically', 'abiotrophy', 'abiquiu', 'abirritant', 'abirritated', 'abirritation', 'abisag', 'abishag', 'abiston', 'abitibi', 'abiuret', 'abject', 'abjection', 'abjective', 'abjectness', 'abjoint', 'abjudged', 'abjudicate', 'abjudicating', 'abjudicator', 'abjunct', 'abjunctive', 'abjurations', 'abjure', 'abjurement', 'abjurers', 'abjuring', 'abkari', 'abkhas', 'abkhasian', 'abkhazia', 'abl', 'ablactate', 'ablactating', 'ablaqueate', 'ablast', 'ablastin', 'ablate', 'ablates', 'ablation', 'ablatitious', 'ablative', 'ablatives', 'ablaut', 'ablaze', 'ablebodied', 'ableeze', 'ablegates', 'ableminded', 'ablend', 'ablepharia', 'ablepharous', 'ablepsia', 'ableptical', 'abler', 'ablesse', 'ablet', 'ablings', 'ablock', 'ablow', 'ablude', 'abluents', 'ablute', 'ablution', 'ablutions', 'ably', 'abmho', 'abmodalities', 'abn', 'abnakis', 'abnegated', 'abnegating', 'abnegations', 'abnegator', 'abner', 'abnet', 'abnormal', 'abnormalcy', 'abnormalised', 'abnormalism', 'abnormalities', 'abnormalize', 'abnormalizing', 'abnormalness', 'abnormities', 'abnormous', 'abo', 'aboardage', 'abococket', 'abode', 'abodement', 'aboding', 'abogado', 'abohm', 'aboideau', 'aboideaux', 'aboiteau', 'aboiteaux', 'abolish', 'abolished', 'abolishers', 'abolishing', 'abolishments', 'abolitionary', 'abolitionised', 'abolitionism', 'abolitionists', 'abolitionized', 'abolitions', 'abollae', 'abomas', 'abomasal', 'abomasum', 'abomasusi', 'abominability', 'abominableness', 'abominate', 'abominates', 'abomination', 'abominator', 'abomine', 'abongo', 'abonnement', 'aborad', 'aborally', 'aboriginal', 'aboriginally', 'aboriginary', 'aborigines', 'aborn', 'aborsement', 'abort', 'aborter', 'aborticide', 'abortifacient', 'aborting', 'abortional', 'abortionists', 'abortive', 'abortiveness', 'aborts', 'abortuses', 'abote', 'abouchement', 'abought', 'aboulia', 'aboulic', 'abounded', 'abounding', 'abounds', 'about', 'aboutfaced', 'abouts', 'aboutshipped', 'aboutsledge', 'above', 'abovecited', 'abovefound', 'aboveground', 'abovenamed', 'abovequoted', 'aboves', 'abovestairs', 'abovewritten', 'abox', 'abpc', 'abr', 'abracadabra', 'abrachias', 'abradant', 'abrade', 'abrader', 'abrades', 'abraham', 'abrahamidae', 'abrahamitic', 'abrahams', 'abrahan', 'abram', 'abramo', 'abramson', 'abranchial', 'abranchian', 'abranchiate', 'abrasax', 'abrased', 'abrash', 'abrasiometer', 'abrasions', 'abrasively', 'abrasivenesses', 'abrastol', 'abraxas', 'abrazite', 'abrazo', 'abreact', 'abreacting', 'abreactions', 'abreast', 'abrege', 'abrenounce', 'abrenunciation', 'abret', 'abri', 'abricock', 'abridgable', 'abridgeable', 'abridgedly', 'abridgements', 'abridgers', 'abridging', 'abridgments', 'abrin', 'abris', 'abroach', 'abrocoma', 'abrogable', 'abrogated', 'abrogating', 'abrogations', 'abrogator', 'abroma', 'abronia', 'abrook', 'abrosias', 'abrotin', 'abrupt', 'abrupter', 'abruptio', 'abruptiones', 'abruptness', 'abruzzi', 'absa', 'absampere', 'absaroka', 'absarokite', 'abscam', 'abscessed', 'abscessing', 'abscessroot', 'abscise', 'abscises', 'abscising', 'abscision', 'abscissa', 'abscissas', 'abscissin', 'abscissions', 'abscond', 'abscondedly', 'absconder', 'absconding', 'absconsa', 'abscound', 'absee', 'abseiled', 'abseils', 'absences', 'absentation', 'absentee', 'absentees', 'absenter', 'absentia', 'absently', 'absentminded', 'absentmindedness', 'absentness', 'absey', 'abshenry', 'absi', 'absinthe', 'absinthial', 'absinthiate', 'absinthiating', 'absinthiin', 'absinthine', 'absinthismic', 'absinthol', 'absinths', 'absist', 'absit', 'absohm', 'absolent', 'absolutely', 'absoluter', 'absolutest', 'absolutions', 'absolutist', 'absolutistic', 'absolutists', 'absolutization', 'absolutory', 'absolvatory', 'absolved', 'absolver', 'absolves', 'absolvitor', 'absonant', 'absorb', 'absorbable', 'absorbancy', 'absorbed', 'absorbedness', 'absorbencies', 'absorbent', 'absorber', 'absorbing', 'absorbition', 'absorbtion', 'absorptance', 'absorptiometric', 'absorptional', 'absorptive', 'absorptiveness', 'absquatulate', 'abstain', 'abstainer', 'abstaining', 'abstains', 'abstemiously', 'abstention', 'abstentionist', 'abstentious', 'absterged', 'absterges', 'absterse', 'abstersive', 'abstertion', 'abstinences', 'abstinent', 'abstinently', 'abstr', 'abstractable', 'abstractedly', 'abstracter', 'abstractest', 'abstraction', 'abstractionism', 'abstractionists', 'abstractitious', 'abstractively', 'abstractly', 'abstractnesses', 'abstractors', 'abstrahent', 'abstricted', 'abstriction', 'abstrude', 'abstrusely', 'abstrusenesses', 'abstrusest', 'abstrusities', 'absume', 'absurd', 'absurdest', 'absurdist', 'absurdity', 'absurdness', 'absurdum', 'absyrtus', 'abterminal', 'abthainrie', 'abthanage', 'abu', 'abubekr', 'abucco', 'abukir', 'abulfeda', 'abulias', 'abulomania', 'abumbral', 'abuna', 'abundances', 'abundant', 'abundantly', 'abura', 'aburagiri', 'aburst', 'abury', 'abusage', 'abused', 'abusee', 'abusefully', 'abuser', 'abuses', 'abusing', 'abusious', 'abusively', 'abusivenesses', 'abuta', 'abutilons', 'abutments', 'abuttal', 'abutted', 'abutters', 'abuzz', 'abvolt', 'abwab', 'abwatts', 'abydos', 'abyed', 'abying', 'abys', 'abysmal', 'abysms', 'abyssa', 'abysses', 'abyssinian', 'abyssobenthonic', 'abyssopelagic', 'ac', 'acacallis', 'acacatechol', 'acaceae', 'acacia', 'acacias', 'acacin', 'acad', 'academes', 'academial', 'academias', 'academical', 'academicals', 'academicians', 'academicism', 'academie', 'academise', 'academising', 'academist', 'academization', 'academized', 'academus', 'acadia', 'acadian', 'acaena', 'acajous', 'acalculia', 'acaleph', 'acalephae', 'acalephe', 'acalephoid', 'acalia', 'acalycine', 'acalyculate', 'acalypterae', 'acalyptratae', 'acamar', 'acampo', 'acana', 'acanonical', 'acantha', 'acanthaceous', 'acantharia', 'acanthia', 'acanthin', 'acanthion', 'acantho', 'acanthocephala', 'acanthocephali', 'acanthocereus', 'acanthodea', 'acanthodei', 'acanthodian', 'acanthodii', 'acanthoid', 'acanthological', 'acantholysis', 'acanthomas', 'acanthon', 'acanthophis', 'acanthopod', 'acanthopomatous', 'acanthopteran', 'acanthopterous', 'acanthopterygii', 'acanthosis', 'acanthous', 'acanthurus', 'acanthuses', 'acapnia', 'acapnias', 'acapsular', 'acapulco', 'acarapis', 'acardia', 'acardite', 'acarian', 'acariatre', 'acaricide', 'acarida', 'acaridan', 'acaridea', 'acaridomatia', 'acarids', 'acarina', 'acarines', 'acarnan', 'acarocecidium', 'acaroid', 'acarologist', 'acarophilous', 'acarotoxic', 'acarpelous', 'acarus', 'acast', 'acatalectic', 'acatalepsy', 'acatallactic', 'acataphasia', 'acatastasia', 'acate', 'acater', 'acates', 'acatharsy', 'acaudal', 'acaudelescent', 'acaulescent', 'acaulose', 'acaws', 'acbl', 'acca', 'accad', 'accadian', 'acce', 'acceded', 'acceder', 'accedes', 'accel', 'accelerando', 'accelerate', 'acceleratedly', 'accelerating', 'acceleration', 'accelerative', 'acceleratorh', 'acceleratory', 'accelerometer', 'accend', 'accendible', 'accension', 'accent', 'accenting', 'accentor', 'accents', 'accentual', 'accentually', 'accentuated', 'accentuating', 'accentuations', 'accentus', 'acceptabilities', 'acceptable', 'acceptably', 'acceptances', 'acceptancy', 'acceptation', 'accepted', 'acceptee', 'accepter', 'acceptilate', 'acceptilating', 'accepting', 'acceptingness', 'acceptive', 'acceptors', 'accepts', 'accersition', 'access', 'accessable', 'accessarily', 'accessary', 'accessed', 'accessibilities', 'accessible', 'accessibly', 'accession', 'accessioned', 'accessioning', 'accessit', 'accessively', 'accessor', 'accessories', 'accessorily', 'accessorius', 'accessorize', 'accessorizing', 'accessory', 'acciaccaturas', 'accidence', 'accidency', 'accidental', 'accidentalist', 'accidentally', 'accidentals', 'accidentary', 'accidential', 'accidently', 'accidents', 'accidias', 'accidies', 'accinged', 'accipenser', 'accipiter', 'accipitrary', 'accipitrine', 'accise', 'accite', 'acclaim', 'acclaimed', 'acclaimers', 'acclaims', 'acclamations', 'acclamatory', 'acclimatation', 'acclimated', 'acclimates', 'acclimation', 'acclimatisable', 'acclimatise', 'acclimatiser', 'acclimatizable', 'acclimatizations', 'acclimatized', 'acclimatizes', 'acclimature', 'acclinate', 'acclivitous', 'acclivous', 'accoast', 'accokeek', 'accoladed', 'accolated', 'accoll', 'accolled', 'accomac', 'accommodable', 'accommodate', 'accommodately', 'accommodates', 'accommodatingly', 'accommodation', 'accommodationist', 'accommodative', 'accommodativeness', 'accommodators', 'accompanable', 'accompanier', 'accompaniment', 'accompaniments', 'accompanists', 'accompanying', 'accomplement', 'accompli', 'accomplices', 'accomplicity', 'accomplish', 'accomplished', 'accomplishers', 'accomplishing', 'accomplishments', 'accompt', 'accordable', 'accordances', 'accordant', 'accordatura', 'accordature', 'accorder', 'according', 'accordion', 'accordionists', 'accords', 'accorporation', 'accostable', 'accosting', 'accouche', 'accouchements', 'accoucheurs', 'accoucheuses', 'account', 'accountability', 'accountableness', 'accountancies', 'accountant', 'accountantship', 'accounter', 'accounting', 'accountment', 'accounts', 'accouplement', 'accourt', 'accoutered', 'accouterment', 'accouters', 'accoutred', 'accoutrements', 'accoutring', 'accoy', 'accoying', 'accrease', 'accreditable', 'accreditation', 'accredited', 'accrediting', 'accredits', 'accrementition', 'accrescence', 'accrescendo', 'accretal', 'accreted', 'accreting', 'accretionary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_skeleton(word):\n",
        "  return \"_\"*len(word)\n",
        "def clean_word(word):\n",
        "      return word.replace(\"_\",\".\")"
      ],
      "metadata": {
        "id": "TFeDoFoqWyY2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Prediction():\n",
        "  def __init__(self, words, tries_remains = 6):\n",
        "    self.filtered_dict = words.copy()\n",
        "    self.seen_letters = defaultdict(lambda:False)\n",
        "    self.index = 0\n",
        "    self.tries_remains = tries_remains\n",
        "    self.game_status = False #final game status\n",
        "    self.all_letters = list(string.ascii_lowercase)\n",
        "    self.freq_tuples = []\n",
        "    self.full_dictionary = words.copy()\n",
        "    self.guessed = set()\n",
        "    self.baseline_filtered_dict = words.copy()\n",
        "  \n",
        "  def get_skeleton(self, word):\n",
        "    return \"_\"*len(word)\n",
        "\n",
        "  def clean_word(self, word):\n",
        "      return word.replace(\"_\",\".\")\n",
        "\n",
        "\n",
        "  # add $ to the front of a word since this is a Bigram Model.\n",
        "  def convert_word(self, word):\n",
        "      return \"$\" + word\n",
        "\n",
        "  # Collect bigram counts. Because we don't delete keys in dictionary and counter will return 0 for unseen pattern,\n",
        "  # we don't need to add char for dictionary as Unigram Based on Word Length approach.\n",
        "  def bigram(self, corpus):\n",
        "      bigram_counts = defaultdict(Counter)\n",
        "      \n",
        "      for word in corpus:\n",
        "          word = self.convert_word(word)\n",
        "          \n",
        "          # generate a list of bigrams\n",
        "          bigram_list = zip(word[:-1], word[1:])\n",
        "          \n",
        "          # iterate over bigrams\n",
        "          for bigram in bigram_list:\n",
        "              first, second = bigram\n",
        "              bigram_counts[first][second] += 1\n",
        "      return bigram_counts\n",
        "  \n",
        "  def train_bigram(self):\n",
        "      self.bigram_counts = self.bigram(self.full_dictionary)\n",
        "      return\n",
        "  \n",
        "  def train_unigram(self):\n",
        "    self.unigram_counts = self.unigram(self.full_dictionary)\n",
        "    return\n",
        "\n",
        "  # Calculate bigram probability\n",
        "  def bigram_prob(self, key, char, bigram_counts):\n",
        "    prev_word_counts = bigram_counts[key]\n",
        "    total_counts = float(sum(prev_word_counts.values()))\n",
        "\n",
        "    if total_counts == 0:\n",
        "      return float(\"-inf\")\n",
        "    return prev_word_counts[char] / float(sum(prev_word_counts.values())) #all occurences with char next/ all occurences!\n",
        "\n",
        "\n",
        "\n",
        "  def unigram(self, corpus):\n",
        "      unigram_counts = Counter()\n",
        "      \n",
        "      for word in corpus:\n",
        "          for char in word:\n",
        "              unigram_counts[char] += 1\n",
        "              \n",
        "      return unigram_counts\n",
        "\n",
        "  def bigram_guess(self):\n",
        "    available = list(set(string.ascii_lowercase) - self.guessed)\n",
        "    print(available)\n",
        "    # The probabilities of all available characters\n",
        "    bigram_probs = [] \n",
        "    if \"_\" not in self.mask: #base condition\n",
        "      return \"SUCCESS\"\n",
        "    \n",
        "    print(self.mask)\n",
        "\n",
        "    for char in available:\n",
        "        char_prob = 0\n",
        "        for index in range(len(self.mask)):\n",
        "            # The first case is that the first char has not been guessed\n",
        "            if index == 0 and self.mask[index] == '_':\n",
        "                char_prob +=  self.bigram_prob('$', char, self.bigram_counts)\n",
        "                \n",
        "            # The second case is that the other chars have not been guessed\n",
        "            elif self.mask[index] == '_':\n",
        "                # if the previous word has been guessed apply bigram\n",
        "                if not self.mask[index - 1] == '_':\n",
        "                    char_prob +=  self.bigram_prob(self.mask[index - 1], char, self.bigram_counts)\n",
        "                    \n",
        "                # If the previous word has not been guessed apply unigram\n",
        "                else:\n",
        "                    val = float(sum(self.unigram_counts.values()))\n",
        "                    if val == 0:\n",
        "                      char_prob  = float(\"-inf\")\n",
        "                    else:\n",
        "                      char_prob +=  self.unigram_counts[char] / float(sum(self.unigram_counts.values()))\n",
        "                \n",
        "            # The final case is that the character is guessed so we skip this position\n",
        "            else:\n",
        "                continue\n",
        "                \n",
        "        bigram_probs.append(char_prob)\n",
        "    \n",
        "    # Return the max probability of char\n",
        "    return available[bigram_probs.index(max(bigram_probs))]\n",
        "                  \n",
        "\n",
        "  def update_word(self, guess_letter):\n",
        "    temp = \"\"\n",
        "    if guess_letter in self.word:\n",
        "      for index in range(len(self.word)):\n",
        "        if self.word[index] == guess_letter:\n",
        "          temp += self.word[index]\n",
        "        else:\n",
        "          temp += self.mask[index]\n",
        "      return True, temp\n",
        "    else:\n",
        "      return False, self.word\n",
        "  \n",
        "  def run_ngram(self, word, skeleton):\n",
        "    self.word = word #to be accessible everywhere\n",
        "    self.mask = skeleton\n",
        "    self.filter_dictionary() #call after assigning the word!\n",
        "    self.train_unigram()\n",
        "    self.train_bigram()\n",
        "    tries_remains = self.tries_remains\n",
        "    print(tries_remains)\n",
        "    while tries_remains: \n",
        "        guess_letter = self.bigram_guess()\n",
        "        if guess_letter == \"SUCCESS\":\n",
        "          self.successes += 1\n",
        "          self.game_status = True\n",
        "          return\n",
        "        self.guessed.add(guess_letter) #add to set of seen letters\n",
        "        status, new_word = self.update_word(guess_letter)\n",
        "        if status:\n",
        "          self.mask = new_word #updated mask\n",
        "          self.regex_filter()\n",
        "          self.train_unigram()\n",
        "          self.train_bigram()\n",
        "        else:\n",
        "          tries_remains -= 1\n",
        "        if not tries_remains:\n",
        "          self.fails += 1\n",
        "          return\n",
        "  \n",
        "  def reset(self): #reset parameters\n",
        "    self.successes, self.fails, self.game_status = 0, 0, False\n",
        "    return\n",
        "\n",
        "  def random_choose(self):\n",
        "    return random.choice(self.full_dictionary)\n",
        "  \n",
        "  def filter_dictionary(self):\n",
        "    length = len(self.word)\n",
        "    self.full_dictionary = [x for x in self.full_dictionary if len(x) == length]\n",
        "    return\n",
        "  \n",
        "  def regex_filter(self):\n",
        "    temp = self.word.replace(\"_\",\".\")\n",
        "    self.full_dictionary = [x for x in self.full_dictionary if re.match(self.mask, x)]\n",
        "    return\n",
        "\n",
        "\n",
        "  def run_trials(self, n_simulations, train = True): #main function to run trials\n",
        "    n_trials = 6 #hardcoded\n",
        "    if train: #in case self.train_bigram had been called before\n",
        "      self.train_unigram()\n",
        "      self.train_bigram()\n",
        "    \n",
        "    \n",
        "    self.reset() #reset parameters\n",
        "    print(\"Running Trials now\")\n",
        "    for _ in range(n_simulations):\n",
        "      master_word = self.random_choose() #choose a random word from the test set\n",
        "      master_word_skeleton = self.get_skeleton(master_word) #get its skeleton -> rqd?\n",
        "      self.guessed = set() #as a part of init function!\n",
        "      self.filtered_dict = self.baseline_filtered_dict.copy()\n",
        "      self.run_ngram(master_word, master_word_skeleton) #trigger bigram game with 6 tries\n",
        "\n",
        "    print(self.successes)\n",
        "    print(self.fails)"
      ],
      "metadata": {
        "id": "og1YeVPcUfl0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Prediction(words_dict)\n",
        "pred.run_trials(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ktM825zSc87",
        "outputId": "cd1b482f-1618-44cc-e043-97845644b1c0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Trials now\n",
            "6\n",
            "['x', 'y', 'f', 'q', 's', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'e', 'g', 'j', 'u']\n",
            "____________\n",
            "['x', 'y', 'f', 'q', 's', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'g', 'j', 'u']\n",
            "_e_________e\n",
            "['y', 'f', 'q', 's', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'g', 'j', 'u']\n",
            "_e_________e\n",
            "['f', 'q', 's', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'g', 'j', 'u']\n",
            "_e_________e\n",
            "['q', 's', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'g', 'j', 'u']\n",
            "_e_________e\n",
            "['s', 'o', 'i', 'r', 'h', 'a', 'k', 't', 'b', 'n', 'p', 'w', 'd', 'c', 'l', 'z', 'm', 'v', 'g', 'j', 'u']\n",
            "_e_________e\n",
            "['o', 'h', 'a', 't', 'b', 'w', 'd', 'c', 'm', 'g', 'u', 'i', 'r', 'k', 'n', 'p', 'l', 'z', 'v', 'j']\n",
            "_e_________e\n",
            "['h', 'a', 't', 'b', 'w', 'd', 'c', 'm', 'g', 'u', 'i', 'r', 'k', 'n', 'p', 'l', 'z', 'v', 'j']\n",
            "_e__o______e\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(successes/n_simulations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSPfOgNixvEA",
        "outputId": "7e71b82f-1ab5-47ff-827d-5ae3c3946790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15\n"
          ]
        }
      ]
    }
  ]
}